{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imp\n",
    "import torch\n",
    "import PIL.Image\n",
    "import os\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# globals\n",
    "\n",
    "MainModel = imp.load_source('MainModel', '/home/kylesargent/resnet50_128_pytorch/resnet50_128_pytorch.py') \n",
    "model = torch.load('/home/kylesargent/resnet50_128_pytorch/resnet50_128_pytorch.pth')\n",
    "model.cuda()\n",
    "\n",
    "DATASET_PATH = '/home/kylesargent/test/'\n",
    "\n",
    "batch_size = 16\n",
    "alpha = .01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import load_and_transform\n",
    "reload(load_and_transform)\n",
    "from load_and_transform import transform_image, get_image_list, load_image_batch, pairwise_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preprocessing\n",
    "\n",
    "import random\n",
    "\n",
    "images = get_image_list()\n",
    "np.random.shuffle(images)\n",
    "\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(images[:, 1])\n",
    "\n",
    "labels = le.transform(images[:, 1])\n",
    "\n",
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "cluster_model = (nn.Linear(128, 128)).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_repeated_indices(records_array):\n",
    "    # thanks stack exchange\n",
    "    idx_sort = np.argsort(records_array)\n",
    "    sorted_records_array = records_array[idx_sort]\n",
    "    vals, idx_start, count = np.unique(sorted_records_array, return_counts=True,\n",
    "                                    return_index=True)\n",
    "    res = np.split(idx_sort, idx_start[1:])\n",
    "    vals = vals[count > 1]\n",
    "    return [i for l in filter(lambda x: x.size > 1, res) for i in l]\n",
    "\n",
    "get_repeated_indices(np.array([1, 2, 3, 2, 2, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# training loop\n",
    "batch_size = 64\n",
    "lr = .001\n",
    "train_frac = 1\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "from torch.optim import Adam\n",
    "\n",
    "\n",
    "optimizer = Adam(cluster_model.parameters(), lr=lr)\n",
    "\n",
    "for _ in range(2):\n",
    "    for i in tqdm(range(int(len(images) * train_frac) // batch_size)):\n",
    "        cluster_model.weight.data = cluster_model.weight / torch.norm(cluster_model.weight)\n",
    "\n",
    "        batch_labels = np.array(labels[i:i + batch_size])\n",
    "\n",
    "        # repeats = get_repeated_indices(batch_labels)\n",
    "    \n",
    "        if len(repeats) > 0:\n",
    "            # batch_labels = batch_labels[repeats]\n",
    "            batch_labels = torch.from_numpy(batch_labels)\n",
    "\n",
    "            batch_images = images[:, 0][i:i + batch_size]\n",
    "            # batch_images = batch_images[repeats]\n",
    "            \n",
    "            batch_images = load_image_batch(batch_images)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                batch_features = model(batch_images)\n",
    "\n",
    "            batch_features = Variable(batch_features.squeeze())\n",
    "            batch_codes = cluster_model(batch_features)\n",
    "\n",
    "            M = pairwise_distances(batch_codes, batch_codes)\n",
    "\n",
    "            # delta[i][j] is 1 when code i and code j are the same person\n",
    "            delta = (batch_labels.unsqueeze(0) - batch_labels.unsqueeze(1)) == 0\n",
    "            delta = delta.type('torch.FloatTensor').cuda() - torch.eye(len(batch_labels)).cuda()\n",
    "\n",
    "            # print(torch.sum(delta))\n",
    "            # print(len(repeats))\n",
    "            print(\"\\n\")\n",
    "            \n",
    "            loss = torch.sum(delta*M)\n",
    "\n",
    "            # print(loss)\n",
    "            # print(torch.sum(delta))\n",
    "            # print(len(batch_labels) - len(torch.unique(batch_labels)))\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# make a miniature dataset\n",
    "\n",
    "n_people = 10\n",
    "n_images_per_person = 10\n",
    "\n",
    "images = get_image_list(n_people, n_images_per_person)\n",
    "np.random.shuffle(images)\n",
    "labels = le.transform(images[:, 1])\n",
    "\n",
    "# chinese restaurant process\n",
    "\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "cluster_ids = []\n",
    "cluster_codes = []\n",
    "sigma = .01\n",
    "theta = 1.\n",
    "alpha = .5\n",
    "epsilon = .5\n",
    "\n",
    "batch_size = 1\n",
    "\n",
    "predicted_labels = []\n",
    "for i in range(len(images)):\n",
    "    batch_labels = torch.from_numpy(labels[i:i + batch_size])\n",
    "    batch_images = load_image_batch(images[:, 0][i:i + batch_size])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        batch_features = model(batch_images)\n",
    "\n",
    "    batch_features = Variable(batch_features.squeeze())\n",
    "    batch_code = cluster_model(batch_features).cpu().data.numpy()\n",
    "    \n",
    "    \n",
    "    if i == 0:\n",
    "        # set up first cluster\n",
    "        cluster_ids = [[0]]\n",
    "        cluster_codes = [[batch_code]]\n",
    "        cluster_centers = [batch_code]\n",
    "        predicted_labels += [0]\n",
    "    else:\n",
    "        \n",
    "        \n",
    "        # b = len(ks)\n",
    "        cluster_priors = map(lambda ks: (len(ks) - alpha)/(i + theta), cluster_ids)\n",
    "        \n",
    "        B = len(cluster_centers)\n",
    "        cluster_priors += [(B*alpha + theta)/(i + theta)]\n",
    "        assert(np.abs(sum(cluster_priors) - 1) < 1e-5)\n",
    "        \n",
    "        cluster_likelihoods = [\n",
    "            multivariate_normal.logpdf(\n",
    "                batch_code, mean=cluster_center, cov=np.eye(128)*sigma\n",
    "            ) \n",
    "            for cluster_center in cluster_centers\n",
    "        ]\n",
    "        \n",
    "        cluster_likelihoods += [\n",
    "            multivariate_normal.logpdf(\n",
    "                batch_code + epsilon, mean=batch_code, cov=np.eye(128)*sigma\n",
    "            ) \n",
    "        ]\n",
    "        \n",
    "        print(\"ids\", cluster_ids)\n",
    "        print(\"priors\", cluster_priors)\n",
    "        print(\"likelihoods\", cluster_likelihoods)\n",
    "        \n",
    "        assert(len(cluster_likelihoods) == len(cluster_priors))\n",
    "        \n",
    "        cluster_maps = [cluster_likelihood + np.log(cluster_priors[e]) for e, cluster_likelihood in enumerate(cluster_likelihoods)]\n",
    "        cluster_map = np.argmax(cluster_maps)\n",
    "        predicted_labels += [cluster_map]    \n",
    "            \n",
    "        if cluster_map == len(cluster_ids):\n",
    "            cluster_ids += [[i]]\n",
    "            cluster_codes += [[batch_code]]\n",
    "            cluster_centers += [batch_code]\n",
    "        else:\n",
    "            nk = len(cluster_ids[cluster_map])\n",
    "            \n",
    "            cluster_ids[cluster_map] += [i]\n",
    "            cluster_codes[cluster_map] += [batch_code]\n",
    "            cluster_centers[cluster_map] = (nk*cluster_centers[cluster_map] + batch_code)/(nk+1.)\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "metrics.adjusted_mutual_info_score(labels, predicted_labels)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# an experiment to verify that applying the cluster layer separates specific persons better\n",
    "\n",
    "n_people = 5\n",
    "n_images_per_person = 5\n",
    "\n",
    "images = get_image_list(n_people, n_images_per_person)\n",
    "labels = le.transform(images[:, 1])\n",
    "\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "\n",
    "l1 = 0\n",
    "c1 = 0\n",
    "l1p = 0\n",
    "c1p = 0\n",
    "\n",
    "l2 = 0\n",
    "c2 = 0\n",
    "l2p = 0\n",
    "c2p = 0\n",
    "\n",
    "for (image1, label1), (image2, label2) in tqdm(itertools.product(images, images), total=(n_people*n_images_per_person)**2):\n",
    "    batch_images1 = load_image_batch([image1])\n",
    "    batch_images2 = load_image_batch([image2])\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        batch_features1 = model(batch_images1)\n",
    "        batch_features2 = model(batch_images2)\n",
    "\n",
    "    batch_features1 = Variable(batch_features1.squeeze())\n",
    "    batch_features2 = Variable(batch_features2.squeeze())\n",
    "    \n",
    "    batch_code1 = cluster_model(batch_features1).cpu().data.numpy()\n",
    "    batch_code2 = cluster_model(batch_features2).cpu().data.numpy()\n",
    "    \n",
    "    if label1==label2:\n",
    "        if image1 != image2:\n",
    "            l1 += np.linalg.norm(batch_code1 - batch_code2)\n",
    "            c1 += 1\n",
    "            l1p += np.linalg.norm(batch_features1.cpu().data.numpy() - batch_features2.cpu().data.numpy())\n",
    "            c1p += 1\n",
    "    else:\n",
    "        l2 += np.linalg.norm(batch_code1 - batch_code2)\n",
    "        c2 += 1\n",
    "        l2p += np.linalg.norm(batch_features1.cpu().data.numpy() - batch_features2.cpu().data.numpy())\n",
    "        c2p += 1\n",
    "        \n",
    "print(l1/c1)\n",
    "print(l2/c2)\n",
    "print(l1/c1 / (l2/c2))\n",
    "\n",
    "print(l1p/c1p)\n",
    "print(l2p/c2p)\n",
    "print((l1p/c1p)/(l2p/c2p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(19/25."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "200/287."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = []\n",
    "n=4\n",
    "s=400\n",
    "for i in range(s, s+n):\n",
    "    filename = images[i][0]\n",
    "\n",
    "    img = PIL.Image.open(filename)\n",
    "    img = torchvision.transforms.Resize(256)(img)\n",
    "    img = torchvision.transforms.RandomCrop(224)(img)\n",
    "    img = torchvision.transforms.RandomGrayscale(p=0.2)(img)\n",
    "    imgs += [img]\n",
    "    \n",
    "new_im = PIL.Image.new('RGB', (224*n, 224))\n",
    "\n",
    "x_offset = 0\n",
    "for im in imgs:\n",
    "    new_im.paste(im, (x_offset,0))\n",
    "    x_offset += im.size[0]\n",
    "\n",
    "new_im"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
