{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kylesargent/.local/lib/python2.7/site-packages/torch/serialization.py:434: SourceChangeWarning: source code of class 'torch.nn.modules.conv.Conv2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/kylesargent/.local/lib/python2.7/site-packages/torch/serialization.py:434: SourceChangeWarning: source code of class 'torch.nn.modules.batchnorm.BatchNorm2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    }
   ],
   "source": [
    "import imp\n",
    "import torch\n",
    "import PIL.Image\n",
    "import os\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# globals\n",
    "\n",
    "MainModel = imp.load_source('MainModel', '/home/kylesargent/resnet50_128_pytorch/resnet50_128_pytorch.py') \n",
    "model = torch.load('/home/kylesargent/resnet50_128_pytorch/resnet50_128_pytorch.pth')\n",
    "model.cuda()\n",
    "\n",
    "DATASET_PATH = '/home/kylesargent/test/'\n",
    "\n",
    "batch_size = 16\n",
    "alpha = .01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import load_and_transform\n",
    "reload(load_and_transform)\n",
    "from load_and_transform import transform_image, get_image_list, load_image_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "169396"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data preprocessing\n",
    "\n",
    "import random\n",
    "\n",
    "images = get_image_list()\n",
    "np.random.shuffle(images)\n",
    "\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(images[:, 1])\n",
    "\n",
    "labels = le.transform(images[:, 1])\n",
    "\n",
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "cluster_model = nn.Sequential(nn.Linear(128, 128), nn.ReLU(), nn.Linear(128, 128)).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95459840L"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "torch.cuda.memory_allocated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2175.0210, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(913.9758, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(1053.7426, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(591.9983, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(878.9588, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(528.3573, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(3076.2188, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(1482.3081, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(2327.6030, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(2195.5107, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(4286.2510, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(2856.1843, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(4819.1392, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(2780.9839, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(3071.7852, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(1447.4026, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(2308.5391, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(4106.3218, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(3278.9397, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(3482.8806, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(3464.1011, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(1716.9851, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(1261.8921, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(1958.1870, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(1051.1771, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(4304.3926, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(4444.6011, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(39687.5781, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(2959.0933, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(2312.0876, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(2388.1724, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(1964.4923, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(1793.6392, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(1406.0647, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(1288.8689, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(1301.8481, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(1717.8270, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(1234.7102, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(1211.4745, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(1039.2268, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(1339.2245, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(1549.9452, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(686.7303, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(823.8402, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(401.8322, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(581.5983, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(1931.3668, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(542.5526, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(1573.6116, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(439.5620, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(301.9637, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(181.1620, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(1903.0039, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(2573.8135, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(1319.8760, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(2044.3121, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(2892.2449, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(2578.4204, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(1554.0068, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(4407.6230, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(1761.5602, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(2440.7329, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(2436.4287, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(1755.9619, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(2050.3306, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(1922.3071, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(3971.9336, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(3699.0981, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(3427.9507, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(1866.9114, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(2143.0803, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(8636.5947, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(1756.7103, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(1628.9141, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(17211.8613, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(16851.7383, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(18348.7148, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(23706.0820, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(14460.6309, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(9212.6953, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(9124.1416, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(5061.3438, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(5850.7993, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(12537.1523, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(15730.5586, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(13579.5918, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(9847.2168, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(8718.7129, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(10090.4375, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(12115.1846, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(13520.2334, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(17510.4238, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(14962.2031, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(16323.6562, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(17677.1367, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(16546.6230, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(13111.7051, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(10692.0508, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(10094.8848, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(7190.1836, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(6429.1924, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(5580.1006, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(6500.9351, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(7375.3950, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(5219.7666, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(6870.1387, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(7029.5635, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(6613.8706, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(5356.7944, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(6432.8628, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(3686.6843, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(3855.7188, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(5801.8486, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(5235.6348, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(4162.3525, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(4465.0488, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(4347.9287, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(3675.6082, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(3529.8796, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(2985.5547, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(3050.8701, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(1690.3226, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(4634.5483, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(4857.4771, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(5329.0083, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(4016.6309, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(3342.1594, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(2950.5708, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(2347.4236, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(1956.6001, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(1537.0713, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(1925.9296, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(3400.5371, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(1990.4756, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(1813.3469, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(1822.7175, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(5384.4600, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(7379.4990, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(5527.0283, device='cuda:0', grad_fn=<SumBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4472.6084, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(3793.4851, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(3559.1172, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(3014.6162, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(1457.7827, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(1555.8689, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(3385.5601, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(2695.2573, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(2467.9407, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(4695.4893, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(2461.1450, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(1883.0450, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(1880.4624, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(1474.8407, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(1537.7979, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(1585.7096, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(1408.6433, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(1027.5116, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(1272.7267, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(1154.7083, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(1160.8372, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(1370.2025, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(184.2600, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(238.5173, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(205.5141, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(255.2182, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(161.3977, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(180.4752, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(265.4979, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(112.7704, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(144.9758, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(231.6381, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(211.3187, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(797.1373, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(921.9089, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(1256.7173, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(5202.1392, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(3575.1873, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(3102.3782, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(2206.0669, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(1857.9694, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(911.7708, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(538.7991, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(667.5142, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(1205.7424, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(1303.1477, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(773.0028, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(1117.2557, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(1613.4338, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(3818.3721, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(3232.6597, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(2369.9182, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(6052.5215, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(3759.7644, device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(2896.1887, device='cuda:0', grad_fn=<SumBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-102-f5d8e51e0bbf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mdelta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mdiscounts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdelta\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'torch.FloatTensor'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiscounts\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "batch_size = 64\n",
    "from tqdm import tqdm\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.memory_allocated()\n",
    "\n",
    "from torch.optim import Adam\n",
    "\n",
    "alpha = .0001\n",
    "optimizer = Adam(cluster_model.parameters(), lr=.001)\n",
    "\n",
    "for i in range(169396 // batch_size):\n",
    "\n",
    "    batch_labels = torch.from_numpy(labels[i:i + batch_size])\n",
    "    batch_images = load_image_batch(images[:, 0][i:i + batch_size])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        batch_features = model(batch_images)\n",
    "\n",
    "    batch_features = Variable(batch_features.squeeze())\n",
    "    batch_codes = cluster_model(batch_features)\n",
    "    \n",
    "    M = pairwise_distances(batch_codes, batch_codes)\n",
    "    \n",
    "    # delta[i][j] is 1 when code i and code j are the same person\n",
    "    delta = (batch_labels.unsqueeze(0) - batch_labels.unsqueeze(1)) == 0\n",
    "\n",
    "    discounts = (delta - alpha).type('torch.FloatTensor').cuda()\n",
    "    loss = torch.sum(discounts*M)\n",
    "    \n",
    "    print(loss)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(1, 95459840L)\n",
    "(2, 95459840L)\n",
    "(3, 172530176L)\n",
    "(x, 11338029568L)\n",
    "(y, 253794816L)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 64])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(64, 128)\n",
    "\n",
    "torch.mm(x, x.transpose(0, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0, 0],\n",
       "        [0, 1, 0, 1],\n",
       "        [0, 0, 1, 0],\n",
       "        [0, 1, 0, 1]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.Tensor([1,2,4,2])\n",
    "\n",
    "(y.unsqueeze(0) - y.unsqueeze(1)) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(632.4157)\n",
      "tensor(632.4157)\n"
     ]
    }
   ],
   "source": [
    "def pairwise_distances(x,y):\n",
    "    x_norms = torch.sum(x*x, dim=1).unsqueeze(1)\n",
    "    y_norms = torch.sum(y*y, dim=1).unsqueeze(0)    \n",
    "    return x_norms - 2*torch.mm(x, y.transpose(0, 1)) + y_norms"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
